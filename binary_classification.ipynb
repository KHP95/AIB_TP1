{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin = pd.read_csv('./csv/binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                  0\n",
       " Standard deviation of the integrated profile    0\n",
       " Excess kurtosis of the integrated profile       0\n",
       " Skewness of the integrated profile              0\n",
       " Mean of the DM-SNR curve                        0\n",
       " Standard deviation of the DM-SNR curve          0\n",
       " Excess kurtosis of the DM-SNR curve             0\n",
       " Skewness of the DM-SNR curve                    0\n",
       "target_class                                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data_bin.isnull().sum()\n",
    "\n",
    "# Display the number of missing values per column\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.079968</td>\n",
       "      <td>46.549532</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>1.770279</td>\n",
       "      <td>12.614400</td>\n",
       "      <td>26.326515</td>\n",
       "      <td>8.303556</td>\n",
       "      <td>104.857709</td>\n",
       "      <td>0.091574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.652935</td>\n",
       "      <td>6.843189</td>\n",
       "      <td>1.064040</td>\n",
       "      <td>6.167913</td>\n",
       "      <td>29.472897</td>\n",
       "      <td>19.470572</td>\n",
       "      <td>4.506092</td>\n",
       "      <td>106.514540</td>\n",
       "      <td>0.288432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.812500</td>\n",
       "      <td>24.772042</td>\n",
       "      <td>-1.876011</td>\n",
       "      <td>-1.791886</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>7.370432</td>\n",
       "      <td>-3.139270</td>\n",
       "      <td>-1.976976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.929688</td>\n",
       "      <td>42.376018</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>-0.188572</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>14.437332</td>\n",
       "      <td>5.781506</td>\n",
       "      <td>34.960504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.078125</td>\n",
       "      <td>46.947479</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.198710</td>\n",
       "      <td>2.801839</td>\n",
       "      <td>18.461316</td>\n",
       "      <td>8.433515</td>\n",
       "      <td>83.064556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.085938</td>\n",
       "      <td>51.023202</td>\n",
       "      <td>0.473325</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>5.464256</td>\n",
       "      <td>28.428104</td>\n",
       "      <td>10.702959</td>\n",
       "      <td>139.309330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.617188</td>\n",
       "      <td>98.778911</td>\n",
       "      <td>8.069522</td>\n",
       "      <td>68.101622</td>\n",
       "      <td>223.392141</td>\n",
       "      <td>110.642211</td>\n",
       "      <td>34.539844</td>\n",
       "      <td>1191.000837</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile   \n",
       "count                     17898.000000  \\\n",
       "mean                        111.079968   \n",
       "std                          25.652935   \n",
       "min                           5.812500   \n",
       "25%                         100.929688   \n",
       "50%                         115.078125   \n",
       "75%                         127.085938   \n",
       "max                         192.617188   \n",
       "\n",
       "        Standard deviation of the integrated profile   \n",
       "count                                   17898.000000  \\\n",
       "mean                                       46.549532   \n",
       "std                                         6.843189   \n",
       "min                                        24.772042   \n",
       "25%                                        42.376018   \n",
       "50%                                        46.947479   \n",
       "75%                                        51.023202   \n",
       "max                                        98.778911   \n",
       "\n",
       "        Excess kurtosis of the integrated profile   \n",
       "count                                17898.000000  \\\n",
       "mean                                     0.477857   \n",
       "std                                      1.064040   \n",
       "min                                     -1.876011   \n",
       "25%                                      0.027098   \n",
       "50%                                      0.223240   \n",
       "75%                                      0.473325   \n",
       "max                                      8.069522   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve   \n",
       "count                         17898.000000               17898.000000  \\\n",
       "mean                              1.770279                  12.614400   \n",
       "std                               6.167913                  29.472897   \n",
       "min                              -1.791886                   0.213211   \n",
       "25%                              -0.188572                   1.923077   \n",
       "50%                               0.198710                   2.801839   \n",
       "75%                               0.927783                   5.464256   \n",
       "max                              68.101622                 223.392141   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve   \n",
       "count                             17898.000000  \\\n",
       "mean                                 26.326515   \n",
       "std                                  19.470572   \n",
       "min                                   7.370432   \n",
       "25%                                  14.437332   \n",
       "50%                                  18.461316   \n",
       "75%                                  28.428104   \n",
       "max                                 110.642211   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve   \n",
       "count                          17898.000000                   17898.000000  \\\n",
       "mean                               8.303556                     104.857709   \n",
       "std                                4.506092                     106.514540   \n",
       "min                               -3.139270                      -1.976976   \n",
       "25%                                5.781506                      34.960504   \n",
       "50%                                8.433515                      83.064556   \n",
       "75%                               10.702959                     139.309330   \n",
       "max                               34.539844                    1191.000837   \n",
       "\n",
       "       target_class  \n",
       "count  17898.000000  \n",
       "mean       0.091574  \n",
       "std        0.288432  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic statistics of the dataset\n",
    "data_bin.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler를 사용하여 각 특성을 평균이 0이고 표준 편차가 1이 되도록 변환.   \n",
    "주의할 점은, 스케일러는 학습 데이터에만 적합해야 하며, 이 스케일러를 사용하여 테스트 데이터도 변환해야 한다는 것입니다.   \n",
    "이렇게 하는 이유는 테스트 데이터는 학습 과정에서 보이지 않아야 하며, 실제 모델이 처음 보는 데이터에 대한 성능을 정확하게 측정하려면 이와 같은 절차가 필요하기 때문입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.149317</td>\n",
       "      <td>1.334832</td>\n",
       "      <td>-0.669570</td>\n",
       "      <td>-0.400459</td>\n",
       "      <td>-0.319440</td>\n",
       "      <td>-0.370625</td>\n",
       "      <td>-0.072798</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334168</td>\n",
       "      <td>1.802265</td>\n",
       "      <td>-0.011785</td>\n",
       "      <td>-0.370535</td>\n",
       "      <td>-0.371102</td>\n",
       "      <td>-0.588924</td>\n",
       "      <td>0.504427</td>\n",
       "      <td>0.211581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.314372</td>\n",
       "      <td>-1.053322</td>\n",
       "      <td>-0.145233</td>\n",
       "      <td>-0.116593</td>\n",
       "      <td>-0.322107</td>\n",
       "      <td>-0.235328</td>\n",
       "      <td>-0.125996</td>\n",
       "      <td>-0.391373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000694</td>\n",
       "      <td>1.553254</td>\n",
       "      <td>-0.513409</td>\n",
       "      <td>-0.390178</td>\n",
       "      <td>-0.304404</td>\n",
       "      <td>-0.275666</td>\n",
       "      <td>-0.312265</td>\n",
       "      <td>-0.481300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.871402</td>\n",
       "      <td>-0.858879</td>\n",
       "      <td>0.115609</td>\n",
       "      <td>-0.104866</td>\n",
       "      <td>-0.388010</td>\n",
       "      <td>-0.763111</td>\n",
       "      <td>1.324026</td>\n",
       "      <td>1.386794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile   \n",
       "0                         1.149317  \\\n",
       "1                        -0.334168   \n",
       "2                        -0.314372   \n",
       "3                         1.000694   \n",
       "4                        -0.871402   \n",
       "\n",
       "    Standard deviation of the integrated profile   \n",
       "0                                       1.334832  \\\n",
       "1                                       1.802265   \n",
       "2                                      -1.053322   \n",
       "3                                       1.553254   \n",
       "4                                      -0.858879   \n",
       "\n",
       "    Excess kurtosis of the integrated profile   \n",
       "0                                   -0.669570  \\\n",
       "1                                   -0.011785   \n",
       "2                                   -0.145233   \n",
       "3                                   -0.513409   \n",
       "4                                    0.115609   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve   \n",
       "0                            -0.400459                  -0.319440  \\\n",
       "1                            -0.370535                  -0.371102   \n",
       "2                            -0.116593                  -0.322107   \n",
       "3                            -0.390178                  -0.304404   \n",
       "4                            -0.104866                  -0.388010   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve   \n",
       "0                                -0.370625  \\\n",
       "1                                -0.588924   \n",
       "2                                -0.235328   \n",
       "3                                -0.275666   \n",
       "4                                -0.763111   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \n",
       "0                             -0.072798                      -0.287438  \n",
       "1                              0.504427                       0.211581  \n",
       "2                             -0.125996                      -0.391373  \n",
       "3                             -0.312265                      -0.481300  \n",
       "4                              1.324026                       1.386794  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features and the target\n",
    "X = data_bin.drop(\"target_class\", axis=1)\n",
    "y = data_bin[\"target_class\"]\n",
    "\n",
    "# Initialize a new StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the scaled features into a DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Display the first few rows of the scaled features\n",
    "X_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 특성이 평균 0과 표준 편차 1을 가지도록 스케일링되었습니다. 이 데이터를 이용해서 이진 분류 모델을 학습시킬 준비가 되었습니다.\n",
    "\n",
    "다음 단계는 이 데이터를 학습 데이터셋과 테스트 데이터셋으로 분할하는 것입니다. 이를 위해서는 일반적으로 sklearn의 **`train_test_split`** 함수를 사용합니다. 분할 비율을 지정해야 하는데, 일반적으로 전체 데이터셋의 약 70~80%를 학습에 사용하고, 나머지를 테스트에 사용합니다. 이렇게 분할해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14318, 8), (3580, 8), (14318,), (3580,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the resulting datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 성공적으로 분할되었습니다. 학습 데이터셋에는 총 14,318개의 관측치가 있고, 테스트 데이터셋에는 3,580개의 관측치가 있습니다. 이제 이 데이터를 사용하여 이진 분류 모델을 학습시킬 수 있습니다.\n",
    "\n",
    "이진 분류 문제를 해결하기 위한 다양한 알고리즘이 있지만, 여기서는 로지스틱 회귀를 사용해보겠습니다. 로지스틱 회귀는 이진 분류 문제에 널리 사용되는 기법 중 하나로, 특성과 레이블 사이의 로지스틱 함수를 학습합니다.\n",
    "\n",
    "이제 이 로지스틱 회귀 모델을 학습 데이터에 적합시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 모델이 학습 데이터에 성공적으로 적합되었습니다. 이제 이 모델을 사용하여 테스트 데이터에 대한 예측을 수행할 수 있습니다. 그 후, 모델의 성능을 평가하기 위해 여러 가지 메트릭을 사용할 수 있습니다. 일반적으로 이진 분류 문제에서는 정확도, 정밀도, 재현율, F1 점수, ROC 곡선 등을 확인합니다.\n",
    "\n",
    "먼저, 모델을 사용하여 테스트 데이터에 대한 예측을 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display the predictions\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터셋에 대한 예측을 수행했습니다. 이제 이 예측 결과를 사용하여 모델의 성능을 평가할 수 있습니다.\n",
    "\n",
    "이를 위해 여러 가지 메트릭을 사용할 수 있습니다. 여기서는 정확도, 정밀도, 재현율, F1 점수를 계산해보겠습니다. 이러한 메트릭들은 모두 실제 레이블(y_test)와 예측 레이블(y_pred)을 입력으로 사용합니다.\n",
    "\n",
    "또한, ROC 곡선 및 AUC 점수를 계산하여 모델의 성능을 시각적으로 확인할 수 있습니다. ROC 곡선은 False Positive Rate에 대한 True Positive Rate의 그래프이며, AUC(Area Under the Curve) 점수는 이 곡선 아래의 영역을 나타냅니다. AUC 점수는 0.5에서 1.0 사이의 값을 가지며, 값이 클수록 모델의 성능이 좋다는 것을 의미합니다.\n",
    "\n",
    "이제 이러한 메트릭을 계산해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9787709497206704,\n",
       " 0.9359430604982206,\n",
       " 0.8193146417445483,\n",
       " 0.8737541528239202,\n",
       " 0.9744632405445165)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])  # Compute ROC AUC from prediction scores\n",
    "\n",
    "accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 성능 메트릭을 계산한 결과는 다음과 같습니다:\n",
    "\n",
    "- 정확도 (Accuracy): 0.9788\n",
    "- 정밀도 (Precision): 0.9359\n",
    "- 재현율 (Recall): 0.8193\n",
    "- F1 점수: 0.8738\n",
    "- ROC AUC: 0.9745\n",
    "\n",
    "이 메트릭들은 모델의 성능을 다양한 관점에서 평가합니다:\n",
    "\n",
    "- **정확도**: 모든 예측 중 올바른 예측의 비율입니다. 이 경우, 약 97.88%의 예측이 정확했습니다.\n",
    "- **정밀도**: Positive 클래스로 예측한 샘플 중 실제로 Positive 클래스인 샘플의 비율입니다. 이 경우, 약 93.59%의 Positive 클래스 예측이 정확했습니다.\n",
    "- **재현율**: 실제 Positive 클래스인 샘플 중 Positive 클래스로 예측된 샘플의 비율입니다. 이 경우, 실제 Positive 클래스인 샘플 중 약 81.93%를 올바르게 예측했습니다.\n",
    "- **F1 점수**: 정밀도와 재현율의 조화 평균입니다. 이 값은 모델의 정밀도와 재현율을 동시에 고려하므로, 불균형한 데이터셋에서 유용한 메트릭이 될 수 있습니다. 이 경우, F1 점수는 약 0.8738입니다.\n",
    "- **ROC AUC**: Receiver Operating Characteristic Area Under the Curve의 약자로, 이진 분류기의 성능을 평가하는 데 사용되는 메트릭입니다. 이 값이 클수록 모델의 성능이 좋다는 것을 의미합니다. 이 경우, ROC AUC는 약 0.9745입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝\n",
    "\n",
    " 하이퍼파라미터 튜닝은 모델 성능을 향상시키는 데 매우 중요한 단계입니다. 여기서는 Grid Search 방법을 사용하여 로지스틱 회귀 모델의 하이퍼파라미터를 튜닝해보겠습니다. Grid Search는 모든 가능한 하이퍼파라미터 조합을 시도하고, 가장 좋은 성능을 내는 하이퍼파라미터 조합을 찾습니다.\n",
    "\n",
    "로지스틱 회귀의 주요 하이퍼파라미터는 다음과 같습니다:\n",
    "\n",
    "- **C**: 이 값은 규제의 강도를 제어합니다. 값이 작을수록 모델은 더 많은 규제를 받게 되고, 값이 클수록 모델은 덜 규제를 받게 됩니다.\n",
    "- **penalty**: 이 값은 사용할 규제의 종류를 결정합니다. 'l1', 'l2', 'elasticnet', 'none' 중에서 선택할 수 있습니다.\n",
    "\n",
    "이제 이 두 하이퍼파라미터에 대해 Grid Search를 수행해 보겠습니다. 이를 위해, scikit-learn의 **`GridSearchCV`** 함수를 사용할 것입니다. 이 함수는 주어진 모델에 대해 Grid Search를 수행하고, 가장 좋은 성능을 내는 하이퍼파라미터 조합을 찾습니다. 또한, 이 함수는 교차 검증을 사용하여 모델의 성능을 평가하므로, 모델이 학습 데이터에 과적합되지 않았는지 확인할 수 있습니다.\n",
    "\n",
    "먼저, Grid Search를 설정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=42, solver='liblinear'),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l1\", \"l2\"]\n",
    "}\n",
    "\n",
    "# Initialize a new GridSearchCV instance\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42, solver=\"liblinear\"), param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search가 성공적으로 완료되었습니다. 이제 가장 좋은 성능을 낸 하이퍼파라미터 조합을 확인하고, 이를 사용하여 모델의 성능을 평가해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Display the best parameters\n",
    "best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 결과, C가 10이고 penalty가 'l1'일 때 가장 좋은 성능을 보였습니다.\n",
    "\n",
    "이제 이 하이퍼파라미터를 사용하여 모델의 성능을 다시 평가해 보겠습니다. 이를 위해 우선 가장 좋은 성능을 낸 모델을 가져오고, 이 모델을 사용하여 테스트 데이터에 대한 예측을 수행한 후, 이전과 같은 메트릭을 사용하여 성능을 평가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.979050279329609,\n",
       " 0.9361702127659575,\n",
       " 0.822429906542056,\n",
       " 0.8756218905472636,\n",
       " 0.974336106387392)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model to make predictions on the test data\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best)\n",
    "recall_best = recall_score(y_test, y_pred_best)\n",
    "f1_best = f1_score(y_test, y_pred_best)\n",
    "roc_auc_best = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])  # Compute ROC AUC from prediction scores\n",
    "\n",
    "accuracy_best, precision_best, recall_best, f1_best, roc_auc_best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 튜닝 후의 모델 성능 메트릭은 다음과 같습니다:\n",
    "\n",
    "- 정확도 (Accuracy): 0.9791\n",
    "- 정밀도 (Precision): 0.9362\n",
    "- 재현율 (Recall): 0.8224\n",
    "- F1 점수: 0.8756\n",
    "- ROC AUC: 0.9743\n",
    "\n",
    "하이퍼파라미터 튜닝 전과 비교했을 때, 모든 메트릭이 약간 향상된 것을 볼 수 있습니다. 이는 Grid Search를 통한 하이퍼파라미터 튜닝이 모델 성능 향상에 도움이 될 수 있음을 보여줍니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델개선방안\n",
    "1. **다른 모델 사용하기**: 로지스틱 회귀 외에도 여러 가지 분류 알고리즘이 있습니다. 결정 트리, 랜덤 포레스트, 그래디언트 부스팅, 서포트 벡터 머신, 신경망 등을 시도해 볼 수 있습니다. 이들 각각은 다른 유형의 데이터 패턴을 캡처하는 데 장점이 있으므로, 하나의 모델이 작동하지 않는다면 다른 모델을 시도해 보는 것이 좋습니다.\n",
    "2. **하이퍼파라미터 더 튜닝하기**: 이미 Grid Search를 사용하여 하이퍼파라미터를 튜닝했지만, 더 넓은 범위의 하이퍼파라미터를 시도해 볼 수 있습니다. 또는 더 세밀한 그리드를 사용하여 특정 영역의 하이퍼파라미터를 더 자세히 탐색할 수 있습니다.\n",
    "3. **데이터 전처리 개선하기**: 더 좋은 입력 특성을 만들어내는 특성 엔지니어링을 수행하거나, 이상치를 제거하거나, 데이터를 더 잘 정규화하거나 스케일링하는 등의 방법으로 데이터 전처리를 개선할 수 있습니다.\n",
    "4. **데이터를 더 모으기**: 모델이 더 많은 패턴을 학습할 수 있도록 데이터를 더 많이 모으는 것이 도움이 될 수 있습니다. 이는 특히 복잡한 모델에서 유용할 수 있습니다.\n",
    "5. **클래스 불균형 처리하기**: 만약 데이터셋에 클래스 불균형이 있으면, 소수 클래스에 대한 모델의 성능이 저하될 수 있습니다. 이를 해결하기 위해 오버샘플링, 언더샘플링, SMOTE 등의 방법을 사용할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 선택에는 여러 가지 방법이 있지만, 여기서는 두 가지 기본적인 방법을 사용해보겠습니다:\n",
    "\n",
    "1. **상관 관계 분석**: 특성과 목표 변수 사이의 상관 관계를 확인하고, 목표 변수와 높은 상관 관계를 가지는 특성만 선택합니다.\n",
    "2. **재귀적 특성 제거 (Recursive Feature Elimination, RFE)**: 이 방법은 모델을 학습시키고, 가장 중요하지 않은 특성을 하나씩 제거하는 과정을 반복합니다. 이 과정은 목표로 하는 특성의 개수가 남을 때까지 계속됩니다.\n",
    "\n",
    "이제 특성 선택을 위해 상관 관계 분석을 수행해 보겠습니다. 이를 위해 우선 각 특성과 목표 변수 사이의 상관 관계를 계산하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                 -0.673181\n",
       " Excess kurtosis of the DM-SNR curve            -0.390816\n",
       " Standard deviation of the integrated profile   -0.363708\n",
       " Skewness of the DM-SNR curve                   -0.259117\n",
       " Mean of the DM-SNR curve                        0.400876\n",
       " Standard deviation of the DM-SNR curve          0.491535\n",
       " Skewness of the integrated profile              0.709528\n",
       " Excess kurtosis of the integrated profile       0.791591\n",
       "target_class                                     1.000000\n",
       "Name: target_class, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate the correlation between each feature and the target\n",
    "correlations = data_bin.corr()[\"target_class\"].sort_values()\n",
    "\n",
    "# Display the correlations\n",
    "correlations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 특성과 목표 클래스 (펄서인지 아닌지) 사이의 상관 관계를 계산하였습니다. 상관 계수는 -1에서 1 사이의 값을 가지며, 값이 -1에 가까울수록 강한 음의 상관 관계, 값이 1에 가까울수록 강한 양의 상관 관계를 나타냅니다. 0은 두 변수 사이에 상관 관계가 없음을 나타냅니다.\n",
    "\n",
    "이 결과를 보면, 'Excess kurtosis of the integrated profile'와 'Skewness of the integrated profile' 특성이 목표 클래스와 가장 강한 양의 상관 관계를 가지고 있음을 알 수 있습니다. 반면에 'Mean of the integrated profile' 특성은 목표 클래스와 강한 음의 상관 관계를 가지고 있습니다.\n",
    "\n",
    "이제 이 정보를 바탕으로 특성 선택을 수행할 수 있습니다. 예를 들어, 상관 계수가 특정 임계값 이상인 특성만 선택할 수 있습니다. 또는, 상관 계수가 가장 높은 n개의 특성만 선택할 수 있습니다.\n",
    "\n",
    "다음 단계로, 재귀적 특성 제거 (RFE)를 사용하여 특성 선택을 수행해보겠습니다. 이를 위해 sklearn의 **`RFECV`** 함수를 사용하겠습니다. 이 함수는 교차 검증을 사용하여 가장 좋은 특성의 개수를 찾습니다. 이제 이 함수를 사용하여 RFE를 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Mean of the integrated profile',\n",
       "       ' Standard deviation of the integrated profile',\n",
       "       ' Excess kurtosis of the integrated profile',\n",
       "       ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',\n",
       "       ' Standard deviation of the DM-SNR curve',\n",
       "       ' Excess kurtosis of the DM-SNR curve',\n",
       "       ' Skewness of the DM-SNR curve'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the features and the target\n",
    "X = data_bin.drop(\"target_class\", axis=1)\n",
    "y = data_bin[\"target_class\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize a new StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the training data\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize an RFECV instance\n",
    "selector = RFECV(LogisticRegression(random_state=42), step=1, cv=5)\n",
    "\n",
    "# Fit the selector to the data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_features_mask = selector.support_\n",
    "\n",
    "# Apply the mask to get the selected features\n",
    "selected_features = X.columns[selected_features_mask]\n",
    "\n",
    "# Display the selected features\n",
    "selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재귀적 특성 제거 (RFE)를 사용하여 특성 선택을 수행한 결과, 다음 특성들이 선택되었습니다:\n",
    "\n",
    "- Mean of the integrated profile\n",
    "- Standard deviation of the integrated profile\n",
    "- Excess kurtosis of the integrated profile\n",
    "- Skewness of the integrated profile\n",
    "- Mean of the DM-SNR curve\n",
    "- Standard deviation of the DM-SNR curve\n",
    "- Excess kurtosis of the DM-SNR curve\n",
    "- Skewness of the DM-SNR curve\n",
    "\n",
    "원래 데이터셋에는 총 8개의 특성이 있었으므로, RFE가 모든 특성을 유용하다고 판단한 것입니다.\n",
    "\n",
    "이제 이 선택된 특성들로 모델을 다시 학습시키고, 성능을 평가해 볼 수 있습니다. 이를 위해 우선 선택된 특성들로 학습 데이터와 테스트 데이터를 재구성하겠습니다. 그리고 이 데이터를 사용하여 로지스틱 회귀 모델을 다시 학습시키고, 테스트 데이터에 대한 예측을 수행한 후, 성능 메트릭을 계산하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features from the training and test sets\n",
    "X_train_selected = X_train[:, selected_features_mask]\n",
    "X_test_selected = X_test[:, selected_features_mask]\n",
    "\n",
    "# Initialize a new LogisticRegression instance\n",
    "model_selected = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Use the model to predict the outcomes on the test set\n",
    "y_pred_selected = model_selected.predict(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.979608938547486,\n",
       " 0.9442508710801394,\n",
       " 0.8262195121951219,\n",
       " 0.88130081300813,\n",
       " 0.9710009600096001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the metrics\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "precision_selected = precision_score(y_test, y_pred_selected)\n",
    "recall_selected = recall_score(y_test, y_pred_selected)\n",
    "f1_selected = f1_score(y_test, y_pred_selected)\n",
    "roc_auc_selected = roc_auc_score(y_test, model_selected.predict_proba(X_test_selected)[:, 1])  # Compute ROC AUC from prediction scores\n",
    "\n",
    "accuracy_selected, precision_selected, recall_selected, f1_selected, roc_auc_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
