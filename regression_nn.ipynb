{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OT71iqfXR7kX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14LRlHCzR7kb",
        "outputId": "4117fa27-ff71-4d78-82b6-d38bf12f15c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "data = pd.read_csv('./data/Regression_data.csv')\n",
        "\n",
        "# One-hot encode the 'Sex' column\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "sex_encoded = ohe.fit_transform(data[['Sex']])\n",
        "sex_encoded_df = pd.DataFrame(sex_encoded, columns=ohe.categories_[0])\n",
        "\n",
        "# Concatenate the one-hot encoded columns to the original data frame\n",
        "data_encoded = pd.concat([data.drop('Sex', axis=1), sex_encoded_df], axis=1)\n",
        "\n",
        "# Separate the features from the target\n",
        "X = data_encoded.drop('Rings', axis=1)\n",
        "y = data_encoded['Rings']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TensorFlow datasets for training and validation\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
        "\n",
        "# Cache the datasets and batch them\n",
        "train_ds = train_ds.cache().shuffle(3500).batch(32)\n",
        "valid_ds = valid_ds.cache().shuffle(1000).batch(32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the L1 regularizer\n",
        "l1 = tf.keras.regularizers.l1(1e-4)\n",
        "\n",
        "# Define the model\n",
        "nn = keras.models.Sequential([\n",
        "    keras.layers.Dense(64, input_shape=[X_train.shape[1],], kernel_regularizer=l1),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dense(32, kernel_regularizer=l1),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dense(16, kernel_regularizer=l1),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dense(8, kernel_regularizer=l1),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer=keras.optimizers.Adam(0.01), loss='mse')\n",
        "\n",
        "# Define the callbacks\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, verbose=0, mode='auto')\n",
        "e_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "hist = nn.fit(train_ds, validation_data=valid_ds, epochs=200, callbacks=[reduce_lr, e_stop], verbose=0)\n",
        "\n",
        "\n",
        "# # Plot the loss\n",
        "# plt.plot(hist.history['loss'], label='train')\n",
        "# plt.plot(hist.history['val_loss'], label='val')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "dTVzWgfASZlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ofYwDVjR7kb"
      },
      "outputs": [],
      "source": [
        "# # Save the model\n",
        "# nn.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "nn = load_model('best_model_r2.h5')"
      ],
      "metadata": {
        "id": "-lyrk2ugwL5Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5dHZcJrR7kc",
        "outputId": "de5483be-a234-42e7-9cfd-c236b2d32012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 3ms/step\n",
            "MAE: 1.4418711713626624\n",
            "MSE: 4.2280861108604055\n",
            "RMSE: 2.0562310451066548\n",
            "R2 Score: 0.609422256652145\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Use the model to make predictions on the test set\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Flatten the arrays (because the output of the model is a 2D array)\n",
        "y_test_flat = y_test.values.flatten()\n",
        "y_pred_flat = y_pred.flatten()\n",
        "\n",
        "# Calculate the performance metrics\n",
        "mae = mean_absolute_error(y_test_flat, y_pred_flat)\n",
        "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
        "rmse = np.sqrt(mse)  # or mse**0.5\n",
        "r2 = r2_score(y_test_flat, y_pred_flat)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R2 Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOWcP4JoR7kc",
        "outputId": "971bcbf9-b829-443b-89b0-a35f1a1e51e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8558894472508325"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test).flatten()\n",
        "\n",
        "# Calculate the MAPE\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test))\n",
        "\n",
        "# Calculate 1 - MAPE\n",
        "accuracy = 1 - mape\n",
        "\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "nn = load_model('best_model_acc.h5')"
      ],
      "metadata": {
        "id": "ceV3zuDJSJY9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f26a06-74b6-4564-dc7c-ab3092e775ef",
        "id": "G1SCIoImB2Jr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 3ms/step\n",
            "MAE: 1.430631273100821\n",
            "MSE: 4.378940607137779\n",
            "RMSE: 2.092591839594568\n",
            "R2 Score: 0.5954867768191894\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Use the model to make predictions on the test set\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "# Flatten the arrays (because the output of the model is a 2D array)\n",
        "y_test_flat = y_test.values.flatten()\n",
        "y_pred_flat = y_pred.flatten()\n",
        "\n",
        "# Calculate the performance metrics\n",
        "mae = mean_absolute_error(y_test_flat, y_pred_flat)\n",
        "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
        "rmse = np.sqrt(mse)  # or mse**0.5\n",
        "r2 = r2_score(y_test_flat, y_pred_flat)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R2 Score: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac95b862-be17-415a-d02c-ab81b110b346",
        "id": "rdWfkk5TB2Js"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8624262486964518"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Predict on the test data\n",
        "y_pred = nn.predict(X_test).flatten()\n",
        "\n",
        "# Calculate the MAPE\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test))\n",
        "\n",
        "# Calculate 1 - MAPE\n",
        "accuracy = 1 - mape\n",
        "\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optuna 를 해보자"
      ],
      "metadata": {
        "id": "cZx9JMJJo-9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global nn\n",
        "\n",
        "def reg_nn_objective(trial, X_train, X_test, y_train, y_test):\n",
        "    global nn\n",
        "    # Define the L1 regularizer\n",
        "    l1 = tf.keras.regularizers.l1(trial.suggest_float(\"l1\", 1e-5, 1e-1, log=True))\n",
        "\n",
        "    # Define the model\n",
        "    nn = keras.models.Sequential()\n",
        "    nn.add(keras.layers.Dense(trial.suggest_int(\"n_units1\", 4, 64), input_shape=[X_train.shape[1],], kernel_regularizer=l1))\n",
        "    nn.add(keras.layers.BatchNormalization())\n",
        "    nn.add(keras.layers.ReLU())\n",
        "    nn.add(keras.layers.Dense(trial.suggest_int(\"n_units2\", 4, 64), kernel_regularizer=l1))\n",
        "    nn.add(keras.layers.BatchNormalization())\n",
        "    nn.add(keras.layers.ReLU())\n",
        "    nn.add(keras.layers.Dense(trial.suggest_int(\"n_units3\", 4, 64), kernel_regularizer=l1))\n",
        "    nn.add(keras.layers.BatchNormalization())\n",
        "    nn.add(keras.layers.ReLU())\n",
        "    nn.add(keras.layers.Dense(trial.suggest_int(\"n_units4\", 4, 64), kernel_regularizer=l1))\n",
        "    nn.add(keras.layers.BatchNormalization())\n",
        "    nn.add(keras.layers.ReLU())\n",
        "    nn.add(keras.layers.Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    nn.compile(optimizer=keras.optimizers.Adam(trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)), loss='mse')\n",
        "\n",
        "    # Create TensorFlow datasets for training and validation\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
        "    valid_ds = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
        "\n",
        "    # Cache the datasets and batch them\n",
        "    train_ds = train_ds.cache().shuffle(3500).batch(32)\n",
        "    valid_ds = valid_ds.cache().shuffle(1000).batch(32)\n",
        "\n",
        "    # Define the callbacks\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, verbose=0, mode='auto')\n",
        "    e_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    hist = nn.fit(train_ds, validation_data=valid_ds, epochs=200, callbacks=[reduce_lr, e_stop], verbose=0)\n",
        "\n",
        "    # Calculate the R^2 score\n",
        "    y_pred = nn.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Return R^2 to maximize\n",
        "    return r2\n",
        "\n",
        "def save_model_callback(study, trial):\n",
        "    global nn\n",
        "    if study.best_trial.number == trial.number:\n",
        "        nn.save('best_model_r2.h5')  # Save the model\n",
        "\n",
        "# Create the study\n",
        "reg_nn_study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler()\n",
        ")\n",
        "\n",
        "# Optimize the study\n",
        "reg_nn_study.optimize(\n",
        "    lambda trial: reg_nn_objective(trial, X_train, X_test, y_train, y_test),\n",
        "    n_trials=500, callbacks=[save_model_callback]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrUsms-kpBjL",
        "outputId": "c21de311-565c-4e94-abc4-8bf7262e8fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-07-30 12:07:48,369] A new study created in memory with name: no-name-372aa96d-1e22-4487-80a9-e8db5258210a\n",
            "Exception ignored in: <function UniquePtr.__del__ at 0x7869341ba830>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/c_api_util.py\", line 74, in __del__\n",
            "    self.deleter(obj)\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDCZapVnpvTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}